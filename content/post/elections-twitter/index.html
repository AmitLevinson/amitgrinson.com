---
title: Israeli elections on twitter
author: Amit Levinson
date: '2020-03-09'
slug: israeli-elections-on-twitter
categories: []
tags: []
subtitle: ''
summary: ''
authors: []
lastmod: '2020-03-09T19:29:42+02:00'
featured: no
draft: true
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
editor_options: 
  chunk_output_type: console
codefolding_show: show
---

<script src="/rmarkdown-libs/htmlwidgets/htmlwidgets.js"></script>
<link href="/rmarkdown-libs/wordcloud2/wordcloud.css" rel="stylesheet" />
<script src="/rmarkdown-libs/wordcloud2/wordcloud2-all.js"></script>
<script src="/rmarkdown-libs/wordcloud2/hover.js"></script>
<script src="/rmarkdown-libs/wordcloud2-binding/wordcloud2.js"></script>


<p>Israel had its 3rd consecutive election on March 2, 2020.
This is because our Knesset (Hebrew term for house of representatives) wasnâ€™t able to form or hold a government after each of the previous elections. As I wonâ€™t get into the politics of why they didnâ€™t succeed thus far (get it? politics :wink:), I do want to take the opportunity and analyze some tweets posted in the time before and after the elections.</p>
<div id="gathering-the-data" class="section level3">
<h3>Gathering the data <i class="fab fa-twitter"></i></h3>
<p>Twitterâ€™s API only allows scraping for 6-9 days back for free. Therefore, I scraped the data already on March 7, 2020 and saved it for later use. To gather the tweets we can use the <code>{rtweet}</code> package which is amazingly easy to use (<a href="https://rtweet.info/">Check out its website</a>).</p>
<p>Letâ€™s start with the packages weâ€™ll use:</p>
<pre class="r"><code>library(rtweet)
library(tidyverse)
library(tidytext)
library(hrbrthemes)
library(igraph)
library(ggraph)
library(scales)</code></pre>
<p>I could use a consistent theme throughout the post but Iâ€™ll probably be editing each one a bit. With that said, There are some tweaks that will be consistent acorss several of the plots. Therefore, letâ€™s create a theme function as a supplement to all other theme arguments Iâ€™ll use:</p>
<pre class="r"><code>adjust_axis &lt;- function() {
  theme_classic() +
  theme(axis.ticks = element_blank(),
        axis.line = element_blank())}</code></pre>
<p>Next weâ€™ll gather the tweets we need:</p>
<pre class="r"><code>elections_raw &lt;- search_tweets(&quot;×‘×—×™×¨×•×ª&quot;, n = 250000, retryonratelimit = TRUE)</code></pre>
<p>As I mentioned earlier I already scraped the data but wrote the command here in case youâ€™re wondering how to gather it. I used only one term, which in Hebrew is â€œelectionsâ€ and rtweet gathered all tweets containing that word.</p>
<p>Before we begin, I will say this post doesnâ€™t aim to be representative of the discussions that were held during the election period. As a matter of fact, nor does it aim to be representative of the twitter discussion. this is due to two main reasons:<br />
1. Twitter isnâ€™t common in Israel at all. Iâ€™m not sure whatâ€™s the usage rate but itâ€™s definitely not representative of the Israeli population.<br />
2. I searched for only one word - elections (in Hebrew) - which yielded some 16560 tweets. This is definitely not a large enough dataset to claim for representation.</p>
<p>With that said, the data gathered provides an opportunity to look at some Twitter data from the elections period, so why not give it a go.</p>
</div>
<div id="tweet-frequency" class="section level3">
<h3>Tweet frequency</h3>
<p>First, letâ€™s see how the tweets distribute across the time span we searched for. we can create a quick time plot using the <code>ts_plot()</code> from the <code>{rtweet}</code> package:</p>
<pre class="r"><code>elections %&gt;% 
  ts_plot(&quot;2 hours&quot;)+
  geom_line(size = 1, color = &quot;#1DA1F2&quot;)+
  theme_ipsum_rc(plot_title_face = NULL, grid = FALSE)+
  scale_x_datetime(date_breaks = &quot;1 day&quot;,date_labels = &quot;%d %b&quot;)+
  labs(x= NULL, y = NULL,
       title = &quot;Frequency of tweets throughout the Israeli elections week&quot;,
       subtitle = &quot;Tweets aggregated by two-hour interval. only tweets with\nthe word &#39;elections&#39; (in Hebrew) were gathered&quot;)+
  geom_text(aes(x = as.POSIXct(&quot;2020-03-02 23:00:00&quot;), y = 435, label = &quot;10 PM:\nClosing of\npolls&quot;),
            hjust = 0, size = 2.5)+
  geom_vline(xintercept = as.POSIXct(&quot;2020-03-02 22:00&quot;),linetype = &quot;dashed&quot;, size = 0.5, color = &quot;#1DA1F2&quot;)+
  theme(plot.title = element_text(size = 16),
        plot.subtitle = element_text(color = &quot;gray65&quot;))+
  adjust_axis()</code></pre>
<p><img src="/post/elections-twitter/index_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p>Interesting, we see the number of tweets during the closing time is equivalent to that of March 4th early in the morning. Kind of an interesting anomaly which I canâ€™t put my finger on, any suggestions?</p>
</div>
<div id="users-with-most-tweets" class="section level3">
<h3>Users with most tweets</h3>
<p>Next, letâ€™s look at who tweeted the most:</p>
<pre class="r"><code>elections %&gt;% 
  count(screen_name, sort = T) %&gt;% 
  slice(1:15) %&gt;% 
  mutate(screen_name = reorder(screen_name,n)) %&gt;% 
  ggplot(aes(x= screen_name, y= n))+
  geom_col(fill = &quot;#1DA1F2&quot;)+
  coord_flip()+
  scale_y_continuous(breaks = seq(0,180, 30), labels = seq(0,180,30))+
  labs(x = &quot;Screen name&quot;, y = &quot;Number of tweets&quot;, title = &quot;Top 15 users tweeting the word &#39;elections&#39; during the 3rd Israeli elections&quot;)+
  theme(text = element_text(family = &quot;Calibri&quot;),
        axis.text = element_text(size = 12),
        plot.title = element_text(family = &quot;Roboto Condensed&quot;))+
  adjust_axis()</code></pre>
<p><img src="/post/elections-twitter/index_files/figure-html/unnamed-chunk-7-1.png" width="768" /></p>
<p>We see that many news companies tweeted a lot using the word elections: â€˜newisrael13â€™, â€˜kann_newsâ€™, â€˜MaarivOnlineâ€™, â€˜RotterNewsâ€™, â€˜bahazit_newsâ€™, â€˜RotterNetâ€™. I personnaly donâ€™t recognize the rest, but on the other hand I use Twitter mostly to follow <code>R</code> and academic related tweets, not necessarily Israeli politics.</p>
</div>
<div id="common-hashtags" class="section level3">
<h3>Common Hashtags</h3>
<p>When using the <code>{rtweet}</code> package to gather twitter data, one of the variables collected is the hashtags used in tweets. Although it requires a few lines of code to get them out of the text, I think this is an amazing feature that shows the details <a href="https://mikewk.com/">Michael W. Kearney</a> put into the package.</p>
<p>According to <a href="https://en.wikipedia.org/wiki/Hashtag">Wikipedia</a>, a â€˜Hashtagâ€™ â€œis a type of metadata tag used on social networks such as Twitter and other microblogging services.â€ that basically tags the message with a specific theme. This helps to see trends and themes in a macro level.</p>
<p>OK then, letâ€™s see what we have:</p>
<pre class="r"><code>hashtags &lt;- elections %&gt;% 
  select(hashtags) %&gt;% 
  unlist() %&gt;% 
  as.tibble() %&gt;% 
  count(value, name = &quot;Count&quot;, sort = T) %&gt;%
  mutate(value = reorder(value, Count),
         iscorona = ifelse(value == &quot;×§×•×¨×•× ×”&quot;, &quot;y&quot;, &quot;n&quot;)) %&gt;% 
  filter(!is.na(value)) %&gt;% 
  slice(1:20)

ggplot(data = hashtags, aes(x = Count, y = value))+
  geom_col(aes(fill = iscorona), show.legend = FALSE)+
  labs(y = NULL, x = &quot;Number of Tweets&quot;, title = &quot;Top 20 Hashtags associated with tweets addressing the Israeli elections&quot;)+
  scale_fill_manual(values = c(y = &quot;#1DA1F2&quot;, n = &quot;gray75&quot;))+
  theme(text = element_text(family = &quot;Calibri&quot;),
        axis.text = element_text(size = 12),
        plot.title = element_text(family = &quot;Roboto Condensed&quot;))+
  adjust_axis()</code></pre>
<p><img src="/post/elections-twitter/index_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<p>The tweets include pretty much the basics with the two leading ones being â€˜electionsâ€™ and â€˜elections2020â€™. I highlighted in blue an interesting hashtag at the time - <font color="#1DA1F2"> Corona </font>. The elections were held on March 2, 2020, a little bit after the first cases reached Israel. Little did we know how it will affect us (Iâ€™m writing this post on April 07,2020 and weâ€™re still in quarantine heading to lock down.)</p>
</div>
<div id="most-liked-and-retweeted" class="section level3">
<h3>Most liked and retweeted</h3>
<p>Letâ€™s have a look at which tweet was <strong>most liked</strong>. Twitter doesnâ€™t define it as â€˜likesâ€™ but as â€˜favoriteâ€™, or at least in the data that is collected through the {rtweet} package. Since I will want to do this again to get the tweet that was retweeted the most Iâ€™ll create a function that will minimize re-writing the code.<br />
<br>
The function takes in a variable, reorders our dataset according to the variable we declared, extracts the first row and then pulls (also extracts) the status id of that tweet. Lastly, the <code>blogdown::shortcode</code> enables to embed tweets, youtube, etc., so we insert our status id in it. For those just getting into functions notice that within the <code>arrange</code> argument we insert our variable in two curly brackets {{}}. This is a powerful feature of <code>{rlang}</code> when you want to manipulate a variable in a dataframe within a function. Read more about it <a href="https://www.tidyverse.org/blog/2019/06/rlang-0-4-0/">here</a></p>
<pre class="r"><code>get_most &lt;- function(var){
elections %&gt;% 
  arrange(desc({{var}})) %&gt;% 
    .[1,] %&gt;% 
    pull(status_id) %&gt;% 
  blogdown::shortcode(&#39;tweet&#39;,.)
}</code></pre>
<center>
{{% tweet "1234584864415997952" %}}
</center>
<p>So the tweet is by â€˜Amit Segalâ€™ - an Israeli news reporter - and it says:<br />
&gt; <em>â€œMore than anything, Iâ€™m glad there wonâ€™t be anymore elections for my family that suffered in honors a year and a quarter, Reut, Ivri and Inbar :heart_eyes:â€</em></p>
<p>Ha, interestingly he wrote it before the end of the elections. However heâ€™s right as we see today that a government was indeed formed so we wonâ€™t have any elections soon (?).</p>
<p>Now letâ€™s look at the <strong>most re-tweeted</strong> tweet:</p>
<center>
{{% tweet "1233342393740603394" %}}
</center>
<p>The tweet is by Benjamin Netanyahu, at the time the prime minister of Israel, who writes:<br />
&gt; "If the recording of Gantzâ€™s advisor is orcherstrated and fabricated (according to Gantzâ€™s words just now), so why did Gantz fire him?
Gantzâ€™s advisor was fired because he said the truth everyone knows: Gantz canâ€™t be a prime minister. We can. 2 more mandates to the Likkud and we are taking the country out of the plonter, preventing another election and form a government</p>
<p>This came after the exposure of a secret recording of Gantz in a closed meeting, A week or so before election day.</p>
</div>
<div id="wordcloud-and-bigrams" class="section level2">
<h2>Wordcloud and bigrams</h2>
<p>We looked beforehand at some commonly used hashtags, letâ€™s have a look at two more things:</p>
<ol style="list-style-type: decimal">
<li>A word-cloud<br />
</li>
<li>Distribution of words before and after the elections</li>
</ol>
<p>We could try out more algorthims but Iâ€™ll save them for a different post.</p>
<div id="wordcloud" class="section level3">
<h3>Wordcloud</h3>
<p>In order to tackle the wordcloud, Iâ€™ll break up all the tweets into words, filter any Hebrew stop-word and all English words:</p>
<pre class="r"><code>he_stopwords &lt;- read_tsv(&quot;https://raw.githubusercontent.com/gidim/HebrewStopWords/master/heb_stopwords.txt&quot;, col_names = &quot;word&quot;)

election_token &lt;- elections %&gt;% 
  unnest_tokens(word, text) %&gt;% 
  select(word) %&gt;%
  anti_join(he_stopwords) %&gt;% 
  count(word, sort = T) %&gt;%
  filter(n&gt;= 150, !grepl(&quot;([a-z]+)|(×‘×—×™×¨×•×ª)&quot;, word))</code></pre>
<p>Now we can look at our wordcloud using <code>{wordcloud2}</code>:</p>
<p><br></p>
<pre class="r"><code>wordcloud2::wordcloud2(election_token, color = &quot;#1DA1F2&quot;, shape = &quot;circle&quot;)</code></pre>
<div id="htmlwidget-1" style="width:672px;height:480px;" class="wordcloud2 html-widget"></div>
<script type="application/json" data-for="htmlwidget-1">{"x":{"word":["×‘×—×™×¨×•×ª","×××©×œ×”","×¨×‘×™×¢×™×•×ª","×‘×™×‘×™","× ×ª× ×™×”×•","×’× ×¥","××¢×¨×›×•×ª","×”×‘×—×™×¨×•×ª","4","3","×œ×™×‘×¨××Ÿ","×× ×“×˜×™×","××¢×¨×›×ª","2020","×›×—×•×œ","×”×™××™×Ÿ","×××©×œ×ª","×”×œ×™×›×•×“","×”××“×™× ×”","×—×•×§","×”×××©×œ×”","×œ×”×¦×‘×™×¢","××—×“×•×ª","2","×”××©×•×ª×¤×ª","×”×¢×","×”×—×•×§","×”×©×××œ","61","× ×•×¡×¤×•×ª","×œ×”×§×™×","×™××™×Ÿ","×‘×‘×—×™×¨×•×ª","×’×•×©","×§×•×œ×•×ª","×œ×¢×•×“","×©×œ×•×©","×©×××œ","×ª×•×¦××•×ª","1","××•×ª× ×•","×ª×¢××•×œ×ª","×œ×‘×—×™×¨×•×ª","×¡×‘×‘","×”×¤×¢×","×œ×× ×•×¢","×”×¦×™×‘×•×¨","××—×¨","×§××¤×™×™×Ÿ","×‘×™×©×¨××œ","×œ×‘×™×‘×™","×œ×™×›×•×“","×œ×œ×™×›×•×“","××‘×™×Ÿ","×©×‘×™×‘×™","××“×™× ×”","××•×¢×“","58","×”×‘××•×ª","×”×¢×¨×‘×™×","×©×œ×™×©×™×•×ª","×”××©×¤×˜","××—×•×–","××™×¢×•×˜","×”×¢×‘×•×“×”","×”××¤×œ×’×”","×œ× ×ª× ×™×”×•","××™×©×•×","×”×›× ×¡×ª","×©× ×ª× ×™×”×•","×œ×™××™×Ÿ","××¤×œ×’×”","×©×™×”×™×•","×œ×¤×™×“","××¦×‘×™×¢×™×","×œ×”×¨×›×™×‘","× ×™×¦×—","×”×¦×‘×¢×”","×‘×¤×¢×","×”×‘×˜×—×ª","×”×”×¦×‘×¢×”","5","×˜×™×‘×™","×§×•×¨×•× ×”","×—×“×©×•×ª","×ª×•×š","××¤×œ×’×ª","×”×¨×©×™××”","×× ×“×˜","62","×™×•×“×¢×™×","×©×œ×™×©×™×ª","10","×”×¨×™","×”×“××•×§×¨×˜×™×”","60","×™××œ×œ×”","×™×”×•×“×™×ª","×—×™×™×‘×™×","×œ×’×•×©","×œ× ×¦×—","×©×ª×™","×™×§×¨×”","×œ×××©×œ×”","×’×‘×™×¨","×”×§×•×¨×•× ×”","×™××™× ×”","×›×ª×‘","×‘××¢×¨×›×ª","×“××•×§×¨×˜×™×”","×‘×›× ×¡×ª","×‘×§×œ×¤×™","×œ×’× ×¥","×—×•×“×©×™×","×©×¨","×¤×¨×¥"],"freq":[17465,2096,2080,1955,1786,1254,1198,1045,986,960,954,920,891,853,788,746,744,718,612,612,576,568,527,526,524,524,434,428,424,397,395,393,369,338,338,333,323,316,315,299,289,287,282,282,269,263,255,253,252,248,247,236,235,235,235,232,231,231,230,229,229,227,219,218,212,209,209,207,206,206,205,205,204,198,194,193,192,191,189,188,186,181,180,180,179,179,178,176,176,175,172,172,172,169,167,167,166,166,164,164,164,164,163,161,160,160,160,158,157,156,155,154,153,152,152,151],"fontFamily":"Segoe UI","fontWeight":"bold","color":"#1DA1F2","minSize":0,"weightFactor":0.0103063269395935,"backgroundColor":"white","gridSize":0,"minRotation":-0.785398163397448,"maxRotation":0.785398163397448,"shuffle":true,"rotateRatio":0.4,"shape":"circle","ellipticity":0.65,"figBase64":null,"hover":null},"evals":[],"jsHooks":[]}</script>
</div>
<div id="bigram-of-used-words" class="section level3">
<h3>Bigram of used words</h3>
<p>Like we did before, we can break up our text data into two words observations, also known as bi-grams. In order to account for all options, we break up the sentence to fit all possible options. For example, assume we have the following sentence:<br />
â€œDanny went to vote yesterdayâ€<br />
Using the <code>unnest_tokens</code> weâ€™ll break the sentence up to become:
1. Danny went<br />
2. went to
3. to vote
4. vote yesterday</p>
<p>Which gives us all possible options. We will also include two columns consisting of the bi-gram broken up into single words. This will help in filtering out bi-grams containing Hebrew stop words. Iâ€™ll not run through the following code and the next and instead will point you to <a href="http://varianceexplained.org/">David Ronbinson</a> &amp; <a href="https://juliasilge.com/">Julia Silge</a> fantastic <a href="https://www.tidytextmining.com/">â€˜Text Mining with Râ€™ Book</a>.</p>
<pre class="r"><code>elec_bigram &lt;- elections %&gt;%
  select(text) %&gt;% 
  unnest_tokens(bigram, text, token = &quot;ngrams&quot;, n = 2) %&gt;%
  separate(bigram, into = c(&quot;word1&quot;, &quot;word2&quot;), sep = &quot; &quot;, remove = FALSE) %&gt;% 
  filter(!word1 %in% he_stopwords$word,
         !word2 %in% he_stopwords$word,
         !grepl(&quot;[a-z]|×‘×—×™×¨×•×ª&quot;, bigram)) %&gt;% 
  count(word1, word2, sort = T) %&gt;% 
  slice(1:45) %&gt;%
  graph_from_data_frame()

p_arrow &lt;- arrow(type = &quot;closed&quot;, length = unit(.1, &quot;inches&quot;))

ggraph(elec_bigram, layout = &quot;fr&quot;)+
  geom_edge_link(aes(edge_alpha = n), arrow = p_arrow, end_cap = circle(.04, &quot;inches&quot;), show.legend = FALSE)+
  geom_node_point(color = &quot;lightblue&quot;, size = 3)+
  geom_node_text(aes(label = name), vjust = 1, hjust = 1, family = &quot;Calibri&quot;)+
  theme_void()+
  labs(title = &quot;Bigram from Twitter data&quot;)+
  theme(text = element_text(family = &quot;Calibri&quot;),
        plot.title = element_text(hjust = 0.5 , face = &quot;bold&quot;, size = 18))</code></pre>
<div class="figure"><span id="fig:unnamed-chunk-12"></span>
<img src="/post/elections-twitter/index_files/figure-html/unnamed-chunk-12-1.png" alt="Graph excludes Hebrew stop words and the word 'elections'" width="672" />
<p class="caption">
Figure 1: Graph excludes Hebrew stop words and the word â€˜electionsâ€™
</p>
</div>
<p><br></p>
<p>So what are we looking at?<br />
* We have discussions regarding the <strong>number of chairs a govenrment will have (62/61/60/58)</strong> connected to mentions of the number of political campaigns (2/3), discussions of united and limited government and the forming of in general.<br />
* We see <strong>mentions of individuals</strong> such as â€˜Yair Lapidâ€™, â€œAmir peretzâ€, â€œBenjamin Netanyahuâ€, â€œAmit Segalâ€ (Both we discussed earlier), â€œNatan Eshelâ€ <strong>but no mention of the main candidate running against Netanyahu - â€œBenny Gantzâ€</strong>. Thatâ€™s actually kind of odd so I ran the analysis again to search for Gantz and found that although he appears in 744 different bigrams, they all include different combinations of him!<br />
* We also see parties mentioned such as â€œMeretzâ€, â€œGesherâ€ and â€œLaborâ€ who ran together this time around, â€œOtzma Yehuditâ€, â€œUnited Torah Judaismâ€, and the â€œJoint Listâ€. <strong>Thereâ€™s no mention of two leading parties - â€œKahol Lavanâ€ &amp; â€œThe Likkudâ€.</strong>, despite the mentioning of the latterâ€™s leader. This is inline with why Gantz doesnâ€™t appear - although the words appear many times, all combinations are somewhat different from one another.<br />
* Mentions of Netanyahuâ€™s indicment and the personal law connected to him.<br />
* Mentions Iâ€™d categorize as â€˜otherâ€™ such as â€œTerrorist supportersâ€, â€œWill of the peopleâ€, â€œFake newsâ€, â€œLast yearâ€, etc.
<br></p>
<p>Actaully, this turned out more interesting than I thought. Several questions arose while looking at it: Several words are missing such as the main parties names (Likkud &amp; Kahol-Lavan), The leading oponent running against Benjamin Netanyahu - Benny Gantz - and other questions such as with whom are specific terms associated. Before we close up Iâ€™ll look at one question that troubles me - <strong>Why doesnâ€™t Gantz appear in our list</strong> ğŸ˜²?</p>
<div id="benny-gantzs-disappearance" class="section level4">
<h4>Benny Gantzâ€™s disappearance</h4>
<p>In order to see why Benny Gantz doesnâ€™t appear in our bigram plot Iâ€™ll do the following: Iâ€™ll break the text into bigrams and filter only to the bigrams containing the word Gantz. Once we have that we can see why doesnâ€™t he appear in our bigram plot despite appearing in our wordcloud. Before I run the analysis and give you the answer think for a moment - What was the process of coming up with the bigram? If I chose only the 50 most frequent bigrams, why would a word that appears many times in our text not appear in our bigram list? Maybe even give the previous chunk another glance before I answer it.<br />
<br>
Letâ€™s have a look:</p>
<pre class="r"><code>gantz &lt;-elections %&gt;%
  select(text) %&gt;% 
  unnest_tokens(bigram, text, token = &quot;ngrams&quot;, n = 2) %&gt;%
  separate(bigram, into = c(&quot;word1&quot;, &quot;word2&quot;), sep = &quot; &quot;, remove = FALSE) %&gt;% 
  filter(word1 %in% &quot;×’× ×¥&quot; |
         word2 %in% &quot;×’× ×¥&quot;,
         !grepl(&quot;[a-z]|×‘×—×™×¨×•×ª&quot;, bigram))</code></pre>
<p>The code is similar to what we did earlier only this time we left <strong>bigrams that match the word we want</strong> and not those that donâ€™t match like stop-words. Now that we have our list of bigrams, letâ€™s count how many distinct bigrams include the word ×’× ×¥ (â€˜Gantzâ€™) we have:</p>
<pre class="r"><code>gantz %&gt;% 
  count(bigram, sort = T)</code></pre>
<pre><code>## # A tibble: 0 x 2
## # ... with 2 variables: bigram &lt;chr&gt;, n &lt;int&gt;</code></pre>
<p><strong>AHA!</strong> Now I see what happened. The first bigram is a stop-word and the word Gantz (â€˜Of Gantzâ€™). The second bigram should have been included as it is Gantzâ€™s full name - Benny Gantz, which appears 138 times.<br />
So, why has it been filtered? This is a great question which we can answer if we look at our stop-words we initially used. Letâ€™s see if it has the word ×‘× ×™ (â€˜bennyâ€™ in Hebrew):</p>
<pre class="r"><code>he_stopwords %&gt;% 
  filter(word == &quot;×‘× ×™&quot;)</code></pre>
<pre><code>## # A tibble: 0 x 1
## # ... with 1 variable: word &lt;chr&gt;</code></pre>
<p>Yes it does. At the time of writing this blog post it leaves me in a dilemma - Should I change the stop-words file I used to a different one or maybe create my own? Or should I continue as is? I think leaving it will teach me (and hopefully whoever read this far) a valuable lesson of always checking your stop-words. In a different context the specific word could have been invaluable, but here it didnâ€™t make sense that our leading candidate was filtered, thus my inquire into what happened. In hebrew the word benny means my son, which I wouldnâ€™t describe as a stop-word but whoever made the dataset I guess did.</p>
<p>Letâ€™s look at a last attempt of bigram, only this time with a different stop word dataset:</p>
</div>
</div>
</div>
